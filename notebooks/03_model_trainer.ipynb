{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\python-projects\\\\chest-cancer-classification'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class LogConfig:\n",
    "    root_dir: Path\n",
    "    tensorboard: Path\n",
    "    lightning: Path\n",
    "    mlflow: Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "    params_learning_rate: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cnnClassifier.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from src.cnnClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([Path(self.config.artifacts_root)])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_log_config(self) -> LogConfig:\n",
    "        logs = self.config.logs\n",
    "        create_directories([Path(logs.root_dir)])\n",
    "\n",
    "        logs_config = LogConfig(\n",
    "            root_dir=Path(logs.root_dir),\n",
    "            tensorboard=Path(logs.tensorboard),\n",
    "            lightning=Path(logs.lightning),\n",
    "            mlflow = Path(logs.mlflow)\n",
    "        )\n",
    "\n",
    "        return logs_config\n",
    "\n",
    "\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = Path(self.config.data_ingestion.unzip_dir) / \"Chest-CT-Scan-data\"\n",
    "        create_directories([Path(training.root_dir)])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE,\n",
    "            params_learning_rate=params.LEARNING_RATE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from src.cnnClassifier.components.prepare_base_model import MyImageClassifier\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, MLFlowLogger\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        transform_list = [\n",
    "            transforms.Resize(self.config.params_image_size[:-1]),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "        if getattr(self.config, \"params_is_augmentation\", False):\n",
    "            transform_list = [\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(20),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            ] + transform_list\n",
    "\n",
    "        transform = transforms.Compose(transform_list)\n",
    "        dataset = datasets.ImageFolder(self.config.training_data, transform=transform)\n",
    "\n",
    "        val_size = int(0.2 * len(dataset))\n",
    "        train_size = len(dataset) - val_size\n",
    "\n",
    "        generator = torch.Generator().manual_seed(42)\n",
    "        self.train_dataset, self.val_dataset = random_split(dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.config.params_batch_size, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.config.params_batch_size, num_workers=4, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig, logs: LogConfig):\n",
    "        self.config = config\n",
    "        self.logs = logs\n",
    "        self.model = None\n",
    "        self.datamodule = None\n",
    "\n",
    "    def get_base_model(self):\n",
    "        base_model = torch.load(self.config.updated_base_model_path, weights_only=False)\n",
    "        self.model = MyImageClassifier(model=base_model, config=self.config)\n",
    "\n",
    "    def get_data_module(self):\n",
    "        self.datamodule = TrainingDataModule(self.config)\n",
    "\n",
    "    def train(self):\n",
    "        self.get_base_model()\n",
    "        self.get_data_module()\n",
    "\n",
    "        tb_logger = TensorBoardLogger(self.logs.tensorboard)\n",
    "        mlflow_logger = MLFlowLogger(\n",
    "            experiment_name=\"ChestCancerClassification\",\n",
    "            tracking_uri= str(self.logs.mlflow)\n",
    "            )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            max_epochs=self.config.params_epochs,\n",
    "            accelerator=\"auto\",\n",
    "            logger=[tb_logger, mlflow_logger],\n",
    "            enable_progress_bar=True,\n",
    "            log_every_n_steps=1\n",
    "        )\n",
    "\n",
    "        trainer.fit(self.model, datamodule=self.datamodule)\n",
    "\n",
    "        torch.save(self.model.model, self.config.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    logs_config = config.get_log_config()\n",
    "    training = Training(config=training_config, logs= logs_config)\n",
    "    training.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python-projects\\chest-cancer-classification\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import optuna\n",
    "import mlflow\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig, logs: LogConfig):\n",
    "        self.config = config\n",
    "        self.logs = logs\n",
    "        self.model = None\n",
    "        self.datamodule = None\n",
    "        self.best_val_loss_overall = float('inf')\n",
    "\n",
    "    def get_base_model(self):\n",
    "        base_model = torch.load(self.config.updated_base_model_path, weights_only=False)\n",
    "        self.model = MyImageClassifier(model=base_model, config=self.config)\n",
    "\n",
    "    def get_data_module(self):\n",
    "        self.datamodule = TrainingDataModule(self.config)\n",
    "\n",
    "\n",
    "    def get_loggers(self):\n",
    "        tb_logger = TensorBoardLogger(self.logs.tensorboard)\n",
    "        mlflow_logger = MLFlowLogger(\n",
    "            experiment_name=\"ChestCancerClassification\",\n",
    "            tracking_uri= str(self.logs.mlflow)\n",
    "            )\n",
    "        \n",
    "        return [tb_logger, mlflow_logger]\n",
    "    \n",
    "\n",
    "\n",
    "    def get_checkpoint_callback(self):\n",
    "        checkpoint_dir = getattr(self.config, \"checkpoint_dir\", self.config.root_dir)\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "            save_weights_only=False,\n",
    "            dirpath=checkpoint_dir,\n",
    "            filename=\"best-model-{epoch:02d}-{val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        return checkpoint_callback\n",
    "\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.get_base_model()\n",
    "        self.get_data_module()\n",
    "\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=self.config.params_epochs,\n",
    "            accelerator=\"auto\",\n",
    "            logger=self.get_loggers(),\n",
    "            callbacks=[self.get_checkpoint_callback()],\n",
    "            enable_progress_bar=True,\n",
    "            log_every_n_steps=1\n",
    "        )\n",
    "\n",
    "        trainer.fit(self.model, datamodule=self.datamodule)\n",
    "        best_model_path = None\n",
    "        for cb in trainer.callbacks:\n",
    "            if isinstance(cb, ModelCheckpoint):\n",
    "                best_model_path = cb.best_model_path\n",
    "                break\n",
    "        val_loss = trainer.callback_metrics.get(\"val_loss\", torch.tensor(1.0)).item()\n",
    "        print(f\"Best model saved at: {best_model_path}\")\n",
    "\n",
    "\n",
    "        return val_loss, best_model_path\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def suggest_hyperparameters(self, trial):\n",
    "        config_new = deepcopy(self.config)\n",
    "        config_new.params_learning_rate = trial.suggest_float(\"LEARNING_RATE\", 1e-5, 1e-1)\n",
    "        config_new.params_batch_size = trial.suggest_categorical(\"BATCH_SIZE\", [8, 16, 32])\n",
    "\n",
    "        trial_ckpt_dir = os.path.join(self.config.root_dir, f\"checkpoints_trial_{trial.number}\")\n",
    "        os.makedirs(trial_ckpt_dir, exist_ok=True)\n",
    "        config_new.checkpoint_dir = trial_ckpt_dir\n",
    "\n",
    "        return config_new\n",
    "\n",
    "\n",
    "    def save_best_model_if_needed(self, val_loss, best_model_path):\n",
    "        if val_loss < self.best_val_loss_overall:\n",
    "            self.best_val_loss_overall = val_loss\n",
    "            os.makedirs(os.path.dirname(self.config.trained_model_path), exist_ok=True)\n",
    "            shutil.copy(best_model_path, self.config.trained_model_path)\n",
    "            print(f\"New best model saved with val_loss={val_loss:.4f} at {self.config.trained_model_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def objective(self,trial):\n",
    "        \n",
    "        mlflow.set_tracking_uri(str(self.logs.mlflow))\n",
    "        config_dict = self.suggest_hyperparameters(trial)\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            trainer = Training(config_dict, self.logs)\n",
    "            val_loss, best_model_path = trainer.train()\n",
    "            self.save_best_model_if_needed(val_loss, best_model_path)\n",
    "            print(\"\\n\\n\")\n",
    "            return val_loss\n",
    "        \n",
    "\n",
    "\n",
    "    def run_optuna_study(self, n_trials: int = 5):\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(self.objective, n_trials=n_trials)\n",
    "\n",
    "        print(\"Best trial:\")\n",
    "        print(f\"  Value: {study.best_trial.value}\")\n",
    "        print(f\"  Params: {study.best_trial.params}\")\n",
    "        print(f\"Best model checkpoint can be found in: {self.config.trained_model_path}\")\n",
    "\n",
    "        self.cleanup_trial_checkpoints()\n",
    "\n",
    "\n",
    "\n",
    "    def cleanup_trial_checkpoints(self):\n",
    "        print(\"Cleaning up temporary trial checkpoint directories...\")\n",
    "        trial_dirs = glob.glob(os.path.join(self.config.root_dir, \"checkpoints_trial_*\"))\n",
    "        final_dir = os.path.dirname(self.config.trained_model_path)\n",
    "        for d in trial_dirs:\n",
    "            if os.path.abspath(d) != os.path.abspath(final_dir):\n",
    "                shutil.rmtree(d, ignore_errors=True)\n",
    "        print(\"Cleanup complete. Only the best model directory remains.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-10 16:35:59,539] [13] [common] - INFO - YAML file loaded successfully: config\\config.yaml\n",
      "[2025-06-10 16:35:59,544] [13] [common] - INFO - YAML file loaded successfully: params.yaml\n",
      "[2025-06-10 16:35:59,546] [26] [common] - INFO - Created directory at: artifacts\n",
      "[2025-06-10 16:35:59,547] [26] [common] - INFO - Created directory at: artifacts\\training\n",
      "[2025-06-10 16:35:59,548] [26] [common] - INFO - Created directory at: artifacts\\logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 16:35:59,551] A new study created in memory with name: no-name-8186a51c-d3bd-418a-9b8a-4a3edc66d97e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-10 16:36:01,327] [156] [setup] - INFO - GPU available: True (cuda), used: True\n",
      "[2025-06-10 16:36:01,329] [159] [setup] - INFO - TPU available: False, using: 0 TPU cores\n",
      "[2025-06-10 16:36:01,330] [169] [setup] - INFO - HPU available: False, using: 0 HPUs\n",
      "[2025-06-10 16:36:01,431] [61] [cuda] - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[2025-06-10 16:36:01,437] [104] [model_summary] - INFO - \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | VGG              | 134 M  | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "119 M     Trainable params\n",
      "14.7 M    Non-trainable params\n",
      "134 M     Total params\n",
      "537.075   Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 4: 100%|██████████| 18/18 [00:03<00:00,  5.48it/s, v_num=3714, val_loss=0.901, val_accuracy=0.412, train_loss=0.877][2025-06-10 16:36:41,053] [191] [fit_loop] - INFO - `Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "Epoch 4: 100%|██████████| 18/18 [00:03<00:00,  5.46it/s, v_num=3714, val_loss=0.901, val_accuracy=0.412, train_loss=0.877]\n",
      "Best model saved at: D:\\python-projects\\chest-cancer-classification\\artifacts\\training\\checkpoints_trial_0\\best-model-epoch=00-val_loss=0.9015-v2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 16:36:46,473] Trial 0 finished with value: 0.9014971852302551 and parameters: {'LEARNING_RATE': 0.021987167793433484, 'BATCH_SIZE': 16}. Best is trial 0 with value: 0.9014971852302551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val_loss=0.9015 at artifacts\\training\\model.pth\n",
      "\n",
      "\n",
      "\n",
      "[2025-06-10 16:36:47,576] [156] [setup] - INFO - GPU available: True (cuda), used: True\n",
      "[2025-06-10 16:36:47,577] [159] [setup] - INFO - TPU available: False, using: 0 TPU cores\n",
      "[2025-06-10 16:36:47,577] [169] [setup] - INFO - HPU available: False, using: 0 HPUs\n",
      "[2025-06-10 16:36:47,642] [61] [cuda] - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[2025-06-10 16:36:47,646] [104] [model_summary] - INFO - \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | VGG              | 134 M  | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "119 M     Trainable params\n",
      "14.7 M    Non-trainable params\n",
      "134 M     Total params\n",
      "537.075   Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 4: 100%|██████████| 18/18 [00:03<00:00,  4.53it/s, v_num=1eb7, val_loss=0.901, val_accuracy=0.412, train_loss=0.877][2025-06-10 16:37:30,316] [191] [fit_loop] - INFO - `Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "Epoch 4: 100%|██████████| 18/18 [00:03<00:00,  4.52it/s, v_num=1eb7, val_loss=0.901, val_accuracy=0.412, train_loss=0.877]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 16:37:36,195] Trial 1 finished with value: 0.9014971852302551 and parameters: {'LEARNING_RATE': 0.04801877697893216, 'BATCH_SIZE': 16}. Best is trial 0 with value: 0.9014971852302551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: D:\\python-projects\\chest-cancer-classification\\artifacts\\training\\checkpoints_trial_1\\best-model-epoch=00-val_loss=0.9015.ckpt\n",
      "\n",
      "\n",
      "\n",
      "[2025-06-10 16:37:38,029] [156] [setup] - INFO - GPU available: True (cuda), used: True\n",
      "[2025-06-10 16:37:38,032] [159] [setup] - INFO - TPU available: False, using: 0 TPU cores\n",
      "[2025-06-10 16:37:38,034] [169] [setup] - INFO - HPU available: False, using: 0 HPUs\n",
      "[2025-06-10 16:37:38,223] [61] [cuda] - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[2025-06-10 16:37:38,237] [104] [model_summary] - INFO - \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | VGG              | 134 M  | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "119 M     Trainable params\n",
      "14.7 M    Non-trainable params\n",
      "134 M     Total params\n",
      "537.075   Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 4: 100%|██████████| 18/18 [00:03<00:00,  5.19it/s, v_num=a228, val_loss=0.901, val_accuracy=0.412, train_loss=0.862][2025-06-10 16:38:31,046] [191] [fit_loop] - INFO - `Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "Epoch 4: 100%|██████████| 18/18 [00:03<00:00,  5.18it/s, v_num=a228, val_loss=0.901, val_accuracy=0.412, train_loss=0.862]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 16:38:35,465] Trial 2 finished with value: 0.9014971852302551 and parameters: {'LEARNING_RATE': 0.047168558176861004, 'BATCH_SIZE': 16}. Best is trial 0 with value: 0.9014971852302551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: D:\\python-projects\\chest-cancer-classification\\artifacts\\training\\checkpoints_trial_2\\best-model-epoch=00-val_loss=0.9015.ckpt\n",
      "\n",
      "\n",
      "\n",
      "[2025-06-10 16:38:37,197] [156] [setup] - INFO - GPU available: True (cuda), used: True\n",
      "[2025-06-10 16:38:37,198] [159] [setup] - INFO - TPU available: False, using: 0 TPU cores\n",
      "[2025-06-10 16:38:37,200] [169] [setup] - INFO - HPU available: False, using: 0 HPUs\n",
      "[2025-06-10 16:38:37,388] [61] [cuda] - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[2025-06-10 16:38:37,404] [104] [model_summary] - INFO - \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | VGG              | 134 M  | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "119 M     Trainable params\n",
      "14.7 M    Non-trainable params\n",
      "134 M     Total params\n",
      "537.075   Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 4: 100%|██████████| 35/35 [00:04<00:00,  8.39it/s, v_num=6335, val_loss=0.710, val_accuracy=0.603, train_loss=0.670][2025-06-10 16:39:47,255] [191] [fit_loop] - INFO - `Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "Epoch 4: 100%|██████████| 35/35 [00:11<00:00,  2.93it/s, v_num=6335, val_loss=0.710, val_accuracy=0.603, train_loss=0.670]\n",
      "Best model saved at: D:\\python-projects\\chest-cancer-classification\\artifacts\\training\\checkpoints_trial_3\\best-model-epoch=04-val_loss=0.7103.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 16:39:53,781] Trial 3 finished with value: 0.7103207111358643 and parameters: {'LEARNING_RATE': 0.0402563320857799, 'BATCH_SIZE': 8}. Best is trial 3 with value: 0.7103207111358643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val_loss=0.7103 at artifacts\\training\\model.pth\n",
      "\n",
      "\n",
      "\n",
      "[2025-06-10 16:39:55,573] [156] [setup] - INFO - GPU available: True (cuda), used: True\n",
      "[2025-06-10 16:39:55,575] [159] [setup] - INFO - TPU available: False, using: 0 TPU cores\n",
      "[2025-06-10 16:39:55,576] [169] [setup] - INFO - HPU available: False, using: 0 HPUs\n",
      "[2025-06-10 16:39:55,698] [61] [cuda] - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[2025-06-10 16:39:55,711] [104] [model_summary] - INFO - \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | VGG              | 134 M  | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "119 M     Trainable params\n",
      "14.7 M    Non-trainable params\n",
      "134 M     Total params\n",
      "537.075   Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 4: 100%|██████████| 35/35 [00:04<00:00,  8.62it/s, v_num=c0f3, val_loss=0.681, val_accuracy=0.632, train_loss=0.637][2025-06-10 16:40:53,825] [191] [fit_loop] - INFO - `Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "Epoch 4: 100%|██████████| 35/35 [00:04<00:00,  8.61it/s, v_num=c0f3, val_loss=0.681, val_accuracy=0.632, train_loss=0.637]\n",
      "Best model saved at: D:\\python-projects\\chest-cancer-classification\\artifacts\\training\\checkpoints_trial_4\\best-model-epoch=01-val_loss=0.6809.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 16:40:59,285] Trial 4 finished with value: 0.6809089183807373 and parameters: {'LEARNING_RATE': 0.07927818925746836, 'BATCH_SIZE': 8}. Best is trial 4 with value: 0.6809089183807373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val_loss=0.6809 at artifacts\\training\\model.pth\n",
      "\n",
      "\n",
      "\n",
      "Best trial:\n",
      "  Value: 0.6809089183807373\n",
      "  Params: {'LEARNING_RATE': 0.07927818925746836, 'BATCH_SIZE': 8}\n",
      "Best model checkpoint can be found in: artifacts\\training\\model.pth\n",
      "Cleaning up temporary trial checkpoint directories...\n",
      "Cleanup complete. Only the best model directory remains.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    logs_config = config.get_log_config()\n",
    "    training = Training(config=training_config, logs= logs_config)\n",
    "    training.run_optuna_study()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
